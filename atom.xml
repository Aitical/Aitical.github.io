<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Aitical</title>
  
  <subtitle>未来可期</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.aitical.cn/"/>
  <updated>2019-08-13T14:05:37.000Z</updated>
  <id>http://www.aitical.cn/</id>
  
  <author>
    <name>Aitical</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Pytorch多机多卡</title>
    <link href="http://www.aitical.cn/2019/08/13/Slurm%E9%9B%86%E7%BE%A4%E4%BD%BF%E7%94%A8Pytorch%E5%A4%9A%E6%9C%BA%E5%A4%9A%E5%8D%A1/"/>
    <id>http://www.aitical.cn/2019/08/13/Slurm集群使用Pytorch多机多卡/</id>
    <published>2019-08-13T14:05:37.000Z</published>
    <updated>2019-08-13T14:05:37.000Z</updated>
    
    <content type="html"><![CDATA[<p>多卡加速训练的话，单机多卡比较容易，简单的使用Pytorch自带的DataParallel即可，不过如果想要更多的卡进行训练，不得不需要多机多卡。主要参考<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82ODcxNzAyOQ==" title="https://zhuanlan.zhihu.com/p/68717029">这篇<i class="fa fa-external-link"></i></span>文章，在Slurm上成功实现多机多卡,这里主要是整理和记录</p><h4 id="Pytorch分布式训练"><a href="#Pytorch分布式训练" class="headerlink" title="Pytorch分布式训练"></a>Pytorch分布式训练</h4><p>与单机多卡的区别：</p><ul><li>DataLoader部分需要使用Sampler，保证不同卡处理独立的子集</li><li>模型部分使用<code>DistributedDataParallel</code></li></ul><p>主要代码如下，参考了<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82ODcxNzAyOQ==" title="https://zhuanlan.zhihu.com/p/68717029">这篇<i class="fa fa-external-link"></i></span>文章中的内容</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.data.distributed <span class="keyword">import</span> DistributedSampler</span><br><span class="line"><span class="keyword">from</span> torch.nn.parallel <span class="keyword">import</span> DistributedDataParallel</span><br><span class="line"></span><br><span class="line">RANK = int(os.environ[<span class="string">'SLURM_PROCID'</span>])</span><br><span class="line">LOCAL_RANK = int(os.environ[<span class="string">'SLURM_LOCALID'</span>])</span><br><span class="line">GPU_NUM = int(os.environ[<span class="string">'SLURM_NTASKS'</span>])</span><br><span class="line">IP = os.environ[<span class="string">'SLURM_STEP_NODELIST'</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dist_init</span><span class="params">(host_addr, rank, local_rank, world_size, port=<span class="number">23456</span>)</span>:</span></span><br><span class="line">    host_addr_full = <span class="string">'tcp://'</span> + host_addr + <span class="string">':'</span> + str(port)</span><br><span class="line">    torch.distributed.init_process_group(<span class="string">"nccl"</span>, init_method=host_addr_full,</span><br><span class="line">                                         rank=rank, world_size=world_size)</span><br><span class="line">    torch.cuda.set_device(local_rank)</span><br><span class="line">    <span class="keyword">assert</span> torch.distributed.is_initialized()</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">dist_init(IP, RANK, LOCAL_RANK, GPU_NUM)</span><br><span class="line">    </span><br><span class="line">   <span class="comment"># DataSet</span></span><br><span class="line">datasampler = DistributedSampler(dataset, num_replicas=GPU_NUM, rank=RANK)</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=datasampler)</span><br><span class="line"></span><br><span class="line"><span class="comment"># model </span></span><br><span class="line">model = DistributedDataPrallel(model, </span><br><span class="line">                                   device_ids=[LOCAL_RANK], </span><br><span class="line">                                   output_device=LOCAL_RANK)</span><br></pre></td></tr></table></figure><p>注意几个参数的设置：</p><ul><li>GPU_NUM: 要使用的GPU总数</li><li>RANK： 进程序号，用于进程通信</li><li><p>LOCAL_RANK: 本地设备序号，用于设备分配</p></li><li><p>BATCH_SIZE：大小是指单张卡的大小</p></li><li>IP: 进程节点ip信息</li></ul><p>启动多机多卡时，完成<code>torch.distributed.init_process_group()</code>初始化，接着对DataLoader进行修改，使用DistributedSampler即可，模型部分对应设置即可</p><p>Slurm启动脚本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line"><span class="meta">#</span>SBATCH --job-name=MultiGPU</span><br><span class="line"><span class="meta">#</span>SBATCH --partition=gpu</span><br><span class="line"><span class="meta">#</span>SBATCH -n 32</span><br><span class="line"><span class="meta">#</span>SBATCH --nodes=8 </span><br><span class="line"><span class="meta">#</span>SBATCH --ntasks-per-node=4</span><br><span class="line"><span class="meta">#</span>SBATCH --output= your_path.out</span><br><span class="line"><span class="meta">#</span>SBATCH --error= your_path.err</span><br><span class="line"><span class="meta">#</span>SBATCH --gres=gpu:4</span><br><span class="line"></span><br><span class="line">python ...</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      使用Pytorch(1.1)自带的分布式训练接口，在GPU集群上使用多机多卡训练模型
    
    </summary>
    
      <category term="Pytorch" scheme="http://www.aitical.cn/categories/Pytorch/"/>
    
    
      <category term="ai-research" scheme="http://www.aitical.cn/tags/ai-research/"/>
    
  </entry>
  
  <entry>
    <title>ShuffleNetV2</title>
    <link href="http://www.aitical.cn/2019/07/31/ShuffleNetV2/"/>
    <id>http://www.aitical.cn/2019/07/31/ShuffleNetV2/</id>
    <published>2019-07-31T19:27:27.000Z</published>
    <updated>2019-08-02T18:04:25.000Z</updated>
    
    <content type="html"><![CDATA[<p>原文：<span class="exturl" data-url="aHR0cDovL3h4eC5pdHAuYWMuY24vcGRmLzE4MDcuMTExNjQucGRm" title="http://xxx.itp.ac.cn/pdf/1807.11164.pdf">ShuffleNet V2: Practical Guidelines for Ecient CNN Architecture Design<i class="fa fa-external-link"></i></span></p><h3 id="模型性能指标"><a href="#模型性能指标" class="headerlink" title="模型性能指标"></a>模型性能指标</h3><p>​ 绝大多数的模型压缩和加速的文章中都使用FLOPs(float-point operations)作为模型的评价指标,用来衡量卷积计算量。但是本文开始就通过一组对比试验指出即使是相同MFLOPs的模型，在不同平台上实际的处理速度仍差别很大。<img src="/2019/07/31/ShuffleNetV2/001-ft1.png" alt="GPU和ARM平台上相同MFLOPs的模型处理速度对比"></p><p>文中分析了相同FLOPs时造成模型速度差别的原因：</p><ul><li>有很多影响速度的因素FLOPs指标没能包含，比如并行程度和MAC。例如对于分组卷积，在算力强的平台上MAC会成为运算性能的瓶颈。</li><li>相同FLOPs时在不同平台上进行操作也会有不同的时间。CUDNN针对$3\times3$的卷积进行了优化，所以速度上不是$1\times1$卷积的9倍</li></ul><p>接着指出评价网络的效率时：</p><ul><li>使用更直接的指标，比如上文测试的处理速度</li><li>评价指标时需要针对具体平台进行测试</li></ul><h3 id="加速网络的四点准则"><a href="#加速网络的四点准则" class="headerlink" title="加速网络的四点准则"></a>加速网络的四点准则</h3><p>文中通过实验体现模型的运行时间的主要组成中，不仅仅是FLOPs体现的卷积运算量(卷积运算是主要部分)，也有很多数据有关的I/O操作或者element-wise的操作(ReLU,AddTensor)等。</p><p><img src="/2019/07/31/ShuffleNetV2/ft2.png" alt="测试不同平台上模型运行的消耗来源"></p><h4 id="G1：相同的通道宽度可最小化MAC"><a href="#G1：相同的通道宽度可最小化MAC" class="headerlink" title="G1：相同的通道宽度可最小化MAC"></a>G1：相同的通道宽度可最小化MAC</h4><p>使用$1\times1$卷积核时，记输入通道$c<em>{1}$输出通道$c</em>{2}$，输入尺寸$h, w$，卷积层FLOPs记作$B$就是：</p><script type="math/tex;mode=display">B=1\times1\times c_{1}\times c_{2}\times h \times w</script><p>也即是$B=hwc<em>{1}c</em>{2}$</p><p>卷积层的内存操作过程，输入特征需要$h\times w\times c<em>{1}$输出需要$h\times w\times c</em>{2}$,卷积核自身需要$c<em>{1}c</em>{2}$所以总的内存消耗：</p><script type="math/tex;mode=display">MAC=hw(c_{1}+c_{2})+c_{1}c_{2}</script><p>在FLOPs一定时，也即$B=hwc<em>{1}c</em>{2}$一定，对MAC使用均值不等式，进行简单的变换带入B便可得到</p><script type="math/tex;mode=display">MAC \geq 2\sqrt{hwB}+\frac{B}{hw}</script><p>等号成立条件$c<em>{1}==c</em>{2}$，所以得出$1\times 1$卷积操作输入输出通道数相同时$MAC$最小</p><p>接着文中进行了对比实验，实验网络是10个block组成，每个block是2个$1\times 1$卷积操作，第一个是$c<em>{1}$到$c</em>{2}$,第二个是$c<em>{2}$到$c</em>{1}$. 对比了四种不同比例下的运算处理速度，可以看到$c<em>{1}==c</em>{2}$时速度最快，如下表：</p><p><img src="/2019/07/31/ShuffleNetV2/ft3.png" alt="验证第一点，对不同比例的输入输出通道数进行测试"></p><h4 id="G2：过多的分组增加MAC"><a href="#G2：过多的分组增加MAC" class="headerlink" title="G2：过多的分组增加MAC"></a>G2：过多的分组增加MAC</h4><p>分组卷积有效的减少了FLOPs，成为当前模型加速的一个常用方法，应用在MobileNet、Xception和Shufflenet等这些经典网络结构中。分组有效减少FLoPs所以即使加宽网络宽度也不会使得FLOPs超过未分组时，但是FLOPs不怎么增加时，网络处理速度不一定会加速，反而分组在一定程度上会使速度变慢，如ResNeXt训练时比ResNet慢。具体分析和实验如下：</p><p>分组卷积中FLOPs是:</p><script type="math/tex;mode=display">B=\frac{hwc_{1}}{g}</script><p>在FLOPs固定时，分组计算中MAC:</p><script type="math/tex;mode=display">\begin{align}MAC &=hw(c_{1}+c_{2})+\frac{c_{1}c_{2}}{g} \\&=hwc_{1}+\frac{Bg}{c_{1}}+\frac{B}{hw}\end{align}</script><p>可以看到，此时随着分组$g$的增加$MAC$也会随之增加。</p><p>接着文中对不同的分组数$g$时的速度进行了对比实验，$c$表示$c<em>{1}+c</em>{2}$，保证FLOPs相同时，对比不同的$g$</p><p><img src="/2019/07/31/ShuffleNetV2/ft4.png" alt="验证第一点，对不同比例的输入输出通道数进行测试"></p><p>从表中很清楚的看到，大的分组数降低运行速度。GPU平台上，1分组的是8分组的2倍以上。ARM平台上，8分组的也比1分组的慢30%。</p><p>在设计网络时，针对不同的平台和具体任务选择和设计分组，使用大量分组是不明智的，虽然通道增加，但是有限的性能提升也带来计算成本的快速增大。</p><h4 id="G3：网络分支会降低并行度"><a href="#G3：网络分支会降低并行度" class="headerlink" title="G3：网络分支会降低并行度"></a>G3：网络分支会降低并行度</h4><p>在很多网络中如GoogleNet系列中，多路结构被广泛使用，</p><p>设计实验进行了验证，使用1到4个$1\times 1$的卷积块，分别组成序列和分支结构如下：</p><p><img src="/2019/07/31/ShuffleNetV2/ft5.png" alt="验证第一点，对不同比例的输入输出通道数进行测试"></p><p>每种结构重复十次分别在GPU和ARM平台上进行测试，结果如下表：</p><p><img src="/2019/07/31/ShuffleNetV2/ft6.png" alt="验证第一点，对不同比例的输入输出通道数进行测试"></p><p>可以看到在GPU平台中，分支并行结构对处理速度影响很大，双分支和四分支序列与并行结构各自对比可以看到，并行结构对处理速度的影响，但在ARM平台上影响较小。</p><h4 id="G4：元素级运算不可忽视"><a href="#G4：元素级运算不可忽视" class="headerlink" title="G4：元素级运算不可忽视"></a>G4：元素级运算不可忽视</h4><p>在第二部分刚开始，分析不同平台上的消耗结构中可以看到，尤其是在GPU平台上， element wise操作占用相当一部分。Element wise的操作包括ReLU，AddTensor，这小操作FLOPs很小但是伴随着很大的MAC。</p><p>设计实验部分，文中使用ResNet的bottleneck块进行速度测试，然后将ReLU和shortcut移除后进行对比测试</p><p><img src="/2019/07/31/ShuffleNetV2/ft7.png" alt="验证第一点，对不同比例的输入输出通道数进行测试"></p><p>从结果可以看到，移除ReLU和shortcut操作后，在GPU和ARM平台上都有20%的提升。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>根据前面提到的4点准则，设计网络时</p><ul><li>卷积通道数量前后一样</li><li>注意分组消耗</li><li>减少分支程度</li><li>减少element wise操作</li></ul><p>这些准则在设计的时候还要考虑到具体得平台</p><h3 id="Shufflenet-V2：-一种高效结构"><a href="#Shufflenet-V2：-一种高效结构" class="headerlink" title="Shufflenet V2： 一种高效结构"></a>Shufflenet V2： 一种高效结构</h3><p><strong>shufflenet</strong>广泛使用在终端设备中，轻量级网络设计时有限的设备算力限制了特征提取的通道数，为了增加通道同时不能过度提升FLOPs两个主要的操作被使用： pointwise group conv和 bottleneck-like结构。同时使用channel shuffle操作使不同组操作中的信息可以连通，具体结构如下图(a)和(c)：</p><p><img src="/2019/07/31/ShuffleNetV2/ft8.png" alt="验证第一点，对不同比例的输入输出通道数进行测试"></p><p>根据前面的4点建议，可以看到pointwise的分组卷积核bottleneck结构违反G1和G2。大量使用分组违反G3，同时Add操作在shortcut中也是违反了G4。</p><p><strong>通道分离和Shufflenet V2</strong>如上图(c)和(d)</p><p>对比(a)与(c)结构设计的改进：</p><ul><li><p>(c)中再开始处有channel split操作，将输入特征通道分成了$c-c’$和$c’$，文中使用$c’=\frac{c}{2}$这与$G1$对应</p></li><li><p>取消$1\times 1$卷积的分组操作，与$G2$对应</p></li><li>channel shuffle在concat之后，与$G3$对应</li><li>将element wise Add换成concat与$G4$对应</li></ul><p>同样的对于(b)和(d)也是针对性的进行设计和改进吗，不过在(d)中开始没有channel shuffle，所以最后concat后特征通道数量翻倍。最后是ShuffleNetV2的详细组成部分，如下图</p><p><img src="/2019/07/31/ShuffleNetV2/ft9.png" alt="验证第一点，对不同比例的输入输出通道数进行测试"></p>]]></content>
    
    <summary type="html">
    
      文中指出模型加速和压缩不应仅关注计算量(FLOPs)这一个指标，还应关注如MAC(memory access coss)等其他损失。并根据不同方面的损失通过多组实验给予了模型设计时的4点建议。
    
    </summary>
    
      <category term="PaperReading" scheme="http://www.aitical.cn/categories/PaperReading/"/>
    
    
      <category term="CNN" scheme="http://www.aitical.cn/tags/CNN/"/>
    
  </entry>
  
</feed>
