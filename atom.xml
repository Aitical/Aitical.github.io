<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Aitical</title>
  
  <subtitle>未来可期</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.aitical.cn/"/>
  <updated>2019-07-31T19:27:27.000Z</updated>
  <id>http://www.aitical.cn/</id>
  
  <author>
    <name>Aitical</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ShuffleNetV2</title>
    <link href="http://www.aitical.cn/2019/07/31/ShuffleNetV2/"/>
    <id>http://www.aitical.cn/2019/07/31/ShuffleNetV2/</id>
    <published>2019-07-31T19:27:27.000Z</published>
    <updated>2019-07-31T19:27:27.000Z</updated>
    
    <content type="html"><![CDATA[<p>原文：<span class="exturl" data-url="aHR0cDovL3h4eC5pdHAuYWMuY24vcGRmLzE4MDcuMTExNjQucGRm" title="http://xxx.itp.ac.cn/pdf/1807.11164.pdf">ShuffleNet V2: Practical Guidelines for Ecient CNN Architecture Design<i class="fa fa-external-link"></i></span></p><h3 id="模型性能指标"><a href="#模型性能指标" class="headerlink" title="模型性能指标"></a>模型性能指标</h3><p>​ 绝大多数的模型压缩和加速的文章中都使用FLOPs(float-point operations)作为模型的评价指标,用来衡量卷积计算量。但是本文开始就通过一组对比试验指出即使是相同MFOPs的模型，在不同平台上实际的处理速度仍差别很大。<img src="/2019/07/31/ShuffleNetV2/001-ft1.png" alt="GPU和ARM平台上相同MFLOPs的模型处理速度对比"></p><p>文中分析了相同FLOPs时造成模型速度差别的原因：</p><ul><li>有很多影响速度的因素FLOPs指标没能包含，比如并行程度和MAC。例如对于分组卷积，在算力强的平台上MAC会成为运算性能的瓶颈。</li><li>相同FLOPs时在不同平台上进行操作也会有不同的时间。CUDNN针对3<em>3的卷积进行了优化，所以速度上不是(1</em>1)卷积的9倍</li></ul><p>接着指出评价网络的效率时：</p><ul><li>使用更直接的指标，比如上文测试的处理速度</li><li>评价指标时需要针对具体平台进行测试</li></ul><h3 id="加速网络的四点指导"><a href="#加速网络的四点指导" class="headerlink" title="加速网络的四点指导"></a>加速网络的四点指导</h3><p>文中通过实验体现模型的运行时间的主要组成中，不仅仅是FLOPs体现的卷积运算量(卷积运算是主要部分)，也有很多数据有关的I/O操作或者element-wise的操作(ReLU,AddTensor)等。</p><p><img src="/2019/07/31/ShuffleNetV2/ft2.png" alt="测试不同平台上模型运行的消耗来源"></p><h4 id="G1：输入输出通道相同时MAC最小"><a href="#G1：输入输出通道相同时MAC最小" class="headerlink" title="G1：输入输出通道相同时MAC最小"></a>G1：输入输出通道相同时MAC最小</h4><script type="math/tex;mode=display">MAC=hw(c_{1}+c_{2})+c_{1}c_{2}</script><p>在FLOPs一定时，也即(B=hwc<em>{1}c</em>{2})一定，对MAC使用均值不等式，进行简单的变换带入B便可得到</p><script type="math/tex;mode=display">MAC \geq 2\sqrt{hwB}+\frac{B}{hw}</script><p>等号成立时(c<em>{1}==c</em>{2})得到$1*1$卷积操作输入输出通道数相同时$MAC$s最少</p><p><img src="/2019/07/31/ShuffleNetV2/ft3.png" alt="验证第一点，对不同比例的输入输出通道数进行测试"></p><h4 id="G2："><a href="#G2：" class="headerlink" title="G2："></a>G2：</h4><h4 id="G3："><a href="#G3：" class="headerlink" title="G3："></a>G3：</h4><h4 id="G4："><a href="#G4：" class="headerlink" title="G4："></a>G4：</h4>]]></content>
    
    <summary type="html">
    
      本文指出模型加速和压缩不应仅关注计算量(FLOPs)这一个指标，还应关注如MAC(memory access coss)等其他损失。并根据不同方面的损失通过多组实验给予了模型设计时的4点建议。
    
    </summary>
    
      <category term="PaperReading" scheme="http://www.aitical.cn/categories/PaperReading/"/>
    
    
      <category term="CNN" scheme="http://www.aitical.cn/tags/CNN/"/>
    
  </entry>
  
</feed>
